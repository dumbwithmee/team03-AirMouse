# íŒŒì¼ëª…: train_model.py

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt

# --- ğŸ“Œ ì„¤ì • ---

# 1. ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ìˆëŠ” í´ë”
PROCESSED_DATA_DIR = "D:\\embed\\final\\processed_data"

# 2. í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œì™€ ì´ë¦„
MODEL_SAVE_PATH = "D:\\embed\\final\\gesture_model.h5"

# 3. í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°
EPOCHS = 100  # ì´ í•™ìŠµ íšŸìˆ˜ (ì—í¬í¬)
BATCH_SIZE = 32  # í•œ ë²ˆì— í•™ìŠµí•  ë°ì´í„° ê°œìˆ˜ (ë°°ì¹˜ í¬ê¸°)
VALIDATION_SPLIT = 0.2  # (ì°¸ê³ ) X_test, y_testë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” 0.0


# -----------------

def load_data(data_dir):
    """
    processed_data í´ë”ì—ì„œ .npy íŒŒì¼ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    print(f"'{data_dir}'ì—ì„œ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        X_train = np.load(os.path.join(data_dir, 'X_train.npy'))
        y_train = np.load(os.path.join(data_dir, 'y_train.npy'))
        X_test = np.load(os.path.join(data_dir, 'X_test.npy'))
        y_test = np.load(os.path.join(data_dir, 'y_test.npy'))

        print("ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
        print(f"  - X_train shape: {X_train.shape}")
        print(f"  - y_train shape: {y_train.shape}")
        print(f"  - X_test shape: {X_test.shape}")
        print(f"  - y_test shape: {y_test.shape}")

        return X_train, y_train, X_test, y_test

    except FileNotFoundError as e:
        print(f"[ì˜¤ë¥˜] ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("preprocess_data.pyë¥¼ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None, None, None, None
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ë°ì´í„° ë¡œë“œ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")
        return None, None, None, None


def build_model(input_shape, num_classes):
    """
    LSTM ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤.
    input_shape: (TIMESTEPS, NUM_FEATURES)
    num_classes: ë¶„ë¥˜í•  ì œìŠ¤ì²˜ì˜ ì´ ê°œìˆ˜
    """
    model = Sequential()

    # ì…ë ¥ì¸µ (LSTM)
    # return_sequences=True: ë‹¤ìŒ LSTM ì¸µì´ ìˆë‹¤ë©´ True
    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.3))  # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë“œë¡­ì•„ì›ƒ

    # ë‘ ë²ˆì§¸ LSTM ì¸µ
    model.add(LSTM(64, return_sequences=False))  # ë§ˆì§€ë§‰ LSTM ì¸µì€ False
    model.add(Dropout(0.3))

    # (ì„ íƒì ) ì™„ì „ ì—°ê²°ì¸µ (Dense)
    model.add(Dense(32, activation='relu'))
    model.add(BatchNormalization())  # ë°°ì¹˜ ì •ê·œí™”

    # ì¶œë ¥ì¸µ
    # num_classes ë§Œí¼ì˜ ë…¸ë“œë¡œ ë¶„ë¥˜, softmaxë¡œ í™•ë¥  ì¶œë ¥
    model.add(Dense(num_classes, activation='softmax'))

    print("\nëª¨ë¸ êµ¬ì„± ì™„ë£Œ:")
    model.summary()
    return model


def plot_history(history):
    """
    ëª¨ë¸ í•™ìŠµ ê³¼ì •(ì •í™•ë„, ì†ì‹¤)ì„ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    plt.figure(figsize=(12, 5))

    # 1. ì •í™•ë„ ê·¸ë˜í”„
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # 2. ì†ì‹¤ ê·¸ë˜í”„
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()


def main():
    # 1. ë°ì´í„° ë¡œë“œ
    X_train, y_train, X_test, y_test = load_data(PROCESSED_DATA_DIR)
    if X_train is None:
        return

    # 2. ëª¨ë¸ íŒŒë¼ë¯¸í„° ìë™ ì„¤ì •
    # X_train.shape = (ë°ì´í„°ê°œìˆ˜, TIMESTEPS, NUM_FEATURES)
    # y_train.shape = (ë°ì´í„°ê°œìˆ˜, NUM_CLASSES)
    try:
        timesteps = X_train.shape[1]
        num_features = X_train.shape[2]
        num_classes = y_train.shape[1]

        input_shape = (timesteps, num_features)

        print(f"\nëª¨ë¸ íŒŒë¼ë¯¸í„° í™•ì¸:")
        print(f"  - TIMESTEPS (ìœˆë„ìš° í¬ê¸°): {timesteps}")
        print(f"  - NUM_FEATURES (ì„¼ì„œ ì¶•): {num_features}")
        print(f"  - NUM_CLASSES (ì œìŠ¤ì²˜ ê°œìˆ˜): {num_classes}")

    except IndexError as e:
        print(f"[ì˜¤ë¥˜] ë°ì´í„° í˜•íƒœ(shape)ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")
        print("  - X ë°ì´í„°ê°€ 3ì°¨ì›(samples, timesteps, features)ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return
    except Exception as e:
        print(f"[ì˜¤ë¥˜] íŒŒë¼ë¯¸í„° ì„¤ì • ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")
        return

    # 3. ëª¨ë¸ ë¹Œë“œ
    model = build_model(input_shape, num_classes)

    # 4. ëª¨ë¸ ì»´íŒŒì¼
    #    loss: 'categorical_crossentropy' (ì›-í•« ì¸ì½”ë”©ëœ ë‹¤ì¤‘ ë¶„ë¥˜)
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    # 5. ì½œë°±(Callbacks) ì„¤ì •
    #    - EarlyStopping: ê²€ì¦ ì†ì‹¤(val_loss)ì´ 5ë²ˆ ì—°ì† ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµ ì¡°ê¸° ì¢…ë£Œ
    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

    #    - ModelCheckpoint: ê²€ì¦ ì •í™•ë„(val_accuracy)ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ë§Œ ì €ì¥
    model_check = ModelCheckpoint(filepath=MODEL_SAVE_PATH,
                                  monitor='val_accuracy',
                                  save_best_only=True,
                                  verbose=1)

    print("\nëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 6. ëª¨ë¸ í•™ìŠµ
    history = model.fit(
        X_train, y_train,
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        validation_data=(X_test, y_test),  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ê²€ì¦
        callbacks=[early_stop, model_check]
    )

    print("\nëª¨ë¸ í•™ìŠµ ì™„ë£Œ.")

    # 7. (ì„ íƒì ) ìµœì¢… ëª¨ë¸ í‰ê°€ (ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ ëª¨ë¸ ê¸°ì¤€)
    # ModelCheckpointì˜ restore_best_weights=Trueë¡œ ì¸í•´
    # model ê°ì²´ëŠ” ì´ë¯¸ ìµœìƒì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ê³  ìˆìŒ
    print("\nì €ì¥ëœ ìµœì  ëª¨ë¸ë¡œ ìµœì¢… í‰ê°€:")
    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
    print(f"  - í…ŒìŠ¤íŠ¸ ì†ì‹¤ (Test Loss): {test_loss:.4f}")
    print(f"  - í…ŒìŠ¤íŠ¸ ì •í™•ë„ (Test Accuracy): {test_acc * 100:.2f} %")

    print(f"\nğŸ‰ ìµœì  ëª¨ë¸ì´ '{MODEL_SAVE_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 8. í•™ìŠµ ê³¼ì • ì‹œê°í™”
    print("í•™ìŠµ ê³¼ì • ê·¸ë˜í”„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤...")
    plot_history(history)


if __name__ == '__main__':
    main()